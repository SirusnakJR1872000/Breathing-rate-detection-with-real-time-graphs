{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3787fef-ca57-4ba4-9bcc-7074f2d24368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "x1 = 0.4\n",
    "x2 = 0.6\n",
    "y1 = 0.1\n",
    "y2 = 0.25\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def getFaceROI(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "    if len(faces) > 0:\n",
    "        img = cv2.rectangle(img, (faces[0][0] + int(x1*faces[0][2]), faces[0][1] + int(y1*faces[0][3])), \n",
    "                             (faces[0][0] + int(x2*faces[0][2]), faces[0][1] + int(y2*faces[0][3])), (255, 0, 0), 2)\n",
    "        return [faces[0][0] + int(x1*faces[0][2]), faces[0][1] + int(y1*faces[0][3]), \n",
    "                faces[0][0] + int(x2*faces[0][2]), faces[0][1] + int(y2*faces[0][3])]\n",
    "    else:\n",
    "        return [0, 0, 0, 0]\n",
    "\n",
    "def getColorAverage(frame, color_id):\n",
    "    return frame[:,:,color_id].sum() * 1.0 / (frame.shape[0] * frame.shape[1])\n",
    "\n",
    "def plot_to_image(gsums):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.plot(gsums[-200:], 'g')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Green Channel Intensity')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plot_img = cv2.imread('plot.png')\n",
    "    return plot_img\n",
    "\n",
    "cv2.namedWindow(\"tracking\")\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(fps)\n",
    "step = int(1000/fps)\n",
    "\n",
    "ok, frame = cap.read()\n",
    "if not ok:\n",
    "    print('Failed to read video from camera')\n",
    "    exit()\n",
    "\n",
    "idf = 0\n",
    "gsums = []\n",
    "\n",
    "bbox = [0, 0, 10, 10]\n",
    "m_diff = 0\n",
    "flag = True\n",
    "\n",
    "threshold = 5.0  # Adjust this value based on observations\n",
    "\n",
    "while flag:\n",
    "    ret, frame = cap.read()\n",
    "    if idf == 0:\n",
    "        droi = getFaceROI(frame)\n",
    "        if droi[3] > 0:\n",
    "            bbox = droi\n",
    "    if idf > 0:\n",
    "        df = cv2.absdiff(frame, previous_frame)\n",
    "        m_diff = 1.0 * df.sum() / (df.shape[0] * df.shape[1])\n",
    "        if m_diff > 15:\n",
    "            droi = getFaceROI(frame)\n",
    "            if droi[3] > 0:\n",
    "                bbox = droi\n",
    "\n",
    "    roi = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "    frame = cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2)\n",
    "\n",
    "    green = getColorAverage(roi, 1)\n",
    "    if idf > 50:\n",
    "        gsums.append(green)\n",
    "\n",
    "    idf += 1\n",
    "    previous_frame = frame\n",
    "\n",
    "    if idf > 0 and len(gsums) > 200:\n",
    "        # Analyze breathing pattern\n",
    "        recent_values = np.array(gsums[-200:])\n",
    "        std_dev = np.std(recent_values)\n",
    "        if std_dev > threshold:\n",
    "            message = \"Heavy Breathing\"\n",
    "        else:\n",
    "            message = \"Normal Breathing\"\n",
    "\n",
    "        # Display the message on the frame\n",
    "        cv2.putText(frame, message, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Generate and overlay the plot image\n",
    "        plot_img = plot_to_image(gsums)\n",
    "        plot_img = cv2.resize(plot_img, (frame.shape[1], frame.shape[0] // 3))\n",
    "        frame[frame.shape[0] - plot_img.shape[0]:frame.shape[0], 0:plot_img.shape[1]] = plot_img\n",
    "\n",
    "    cv2.imshow(\"tracking\", frame)\n",
    "    k = cv2.waitKey(step) & 0xff\n",
    "    if k == 27:  # esc pressed\n",
    "        flag = False\n",
    "        break\n",
    "\n",
    "    # exit when tracking window is closed\n",
    "    if cv2.getWindowProperty('tracking', cv2.WND_PROP_AUTOSIZE) < 1:\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "print(\"Execution has finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c4b9b-373d-4d2c-8873-a484c1837499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
